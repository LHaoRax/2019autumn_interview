### 熵、条件熵、信息增益、基尼指数

#### 熵

$$
H(X)=-\Sigma_{i=1}^{n}p_{i}logp_{i}
$$

+ 熵用来表示随机变量的不确定性
+ 熵的单位是比特
+ 熵只依赖于$X$的分布，而与$X$的取值无关
#### 条件熵

$$
H(Y|X)=\Sigma_{i=1}^{n}p_{i}H(Y|X=x_{i})
$$

+ 表示在已知随机变量X的条件下随机变量Y的不确定性
+ 表示得知特征X的信息而使得类Y的信息不确定性减少的程度

#### 信息增益

$$
g(D,A)=H(D)-H(D|A)
$$

+ 表示经验熵与经验条件熵之间的差值
+ **信息增益需要会熟练计算**

#### 基尼指数

$$
Gini(p)=\Sigma_{k=1}^{K}p_{k}(1-p_{k})=1-\Sigma_{k=1}^{K}p_{k}^2
$$

+ 基尼指数与熵一样，表示集合的不确定性，基尼指数越大，不确定性越大

### 混淆矩阵、模型度量指标：准确率、精确率、召回率、F1-Score

#### 混淆矩阵

|        |               AP                |               AN                |
| :----: | :-----------------------------: | :-----------------------------: |
| **PP** |             **TP**              | <font color="red">**FP**</font> |
| **PN** | <font color="red">**FN**</font> |             **TN**              |

+ AP:actual positive，实际正确

+ AN:actual negative，实际错误

+ PP:precision positive，预测正确

+ PN:precision negative，预测错误

+ TP:预测的正确，确实是正确

+ FP:预测的是正确，但其实是错误

+ FN:预测的错误，但其实是正确

+ TN:预测的错误，确实是错误

$$
TP+FP=PP\\
FN+TN=PN\\
TP+FN=AP\\
FP+FN=AN
$$

#### 准确率

$$
accuracy=\frac{TP+TN}{AP+AN}
$$

#### 精确率

$$
precision=\frac{TP}{TP+FP}
$$

> 从公式中可以看出，精确率针对的是预测的PP样本

#### 召回率


$$
recall=\frac{TP}{TP+FN}
$$

> 从公式中可以看出，精确率针对的是实际的AP样本

#### F1-Score

$$
\frac{2}{F_{1}}=\frac{1}{precision}+\frac{1}{recall}
$$

> F1是精确率和召回率的调和均值

### 缺失值处理

+ 缺失值较多的情况下，可以直接丢掉该特征，否则会带来较大的噪声
+ 缺失值较少的情况下，可以对缺失值采取填充
    + 均值
    + 异常值
    + 插值
    + 拟合，是把它当做一个预测问题来处理